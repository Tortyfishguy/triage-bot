from flask import Flask, request, jsonify
import os
import json
import torch
import threading
import requests
import firebase_admin
from firebase_admin import credentials, firestore, storage
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from linebot import LineBotApi, WebhookHandler
from linebot.models import MessageEvent, TextMessage, TextSendMessage

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î Environment Variables
LINE_ACCESS_TOKEN = os.getenv("LINE_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
FIREBASE_CREDENTIALS_JSON = os.getenv("FIREBASE_CREDENTIALS_JSON")
FIREBASE_BUCKET_NAME = os.getenv("FIREBASE_BUCKET_NAME")

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î Firebase Credentials
cred = credentials.Certificate(json.loads(FIREBASE_CREDENTIALS_JSON))
firebase_admin.initialize_app(cred, {"storageBucket": FIREBASE_BUCKET_NAME})
db = firestore.client()
bucket = storage.bucket()

# ‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Firebase Storage
MODEL_DIR = "./esi_model"
MODEL_PATH = f"{MODEL_DIR}/pytorch_model_fp16.bin"
TOKENIZER_PATH = f"{MODEL_DIR}/tokenizer.json"
CONFIG_PATH = f"{MODEL_DIR}/config.json"

def download_model():
    os.makedirs(MODEL_DIR, exist_ok=True)
    
    for file_name in ["pytorch_model_fp16.bin", "tokenizer.json", "config.json"]:
        blob = bucket.blob(f"esi_model/{file_name}")
        destination_path = f"{MODEL_DIR}/{file_name}"
        
        print(f"‚¨áÔ∏è Downloading {file_name} from Firebase Storage...")
        blob.download_to_filename(destination_path)
        print(f"‚úÖ {file_name} downloaded!")

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
print("üöÄ Downloading Model...")
download_model()
device = "cuda" if torch.cuda.is_available() else "cpu"

print("üîÑ Loading Model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_DIR,
    num_labels=5,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32
).to(device)
print("‚úÖ Model Loaded!")

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå CUDA Memory
def clear_cuda_memory():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        print("üßπ Cleared Unused CUDA Memory")

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Flask App
app = Flask(__name__)
line_bot_api = LineBotApi(LINE_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ESI
def classify_esi(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=256).to(device)

    with torch.no_grad():
        outputs = model(**inputs)
    
    predicted_esi = torch.argmax(outputs.logits, dim=1).item() + 1

    # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå CUDA Memory ‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡∏£‡πá‡∏à
    clear_cuda_memory()
    return predicted_esi

# ‚úÖ Webhook ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ + ‡πÉ‡∏ä‡πâ Threading
@app.route("/webhook", methods=["POST"])
def webhook():
    signature = request.headers.get("X-Line-Signature", "No Signature")
    body = request.get_data(as_text=True)

    print(f"üì© Received Webhook: {body}")
    print(f"üîê Signature: {signature}")

    if not signature:
        print("‚ùå Missing X-Line-Signature")
        return "Missing Signature", 400

    # ‡πÉ‡∏ä‡πâ Thread ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Webhook ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
    def handle_message_async():
        try:
            handler.handle(body, signature)
        except Exception as e:
            print(f"‚ö†Ô∏è Error: {str(e)}")

    threading.Thread(target=handle_message_async).start()
    return "OK", 200  # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô timeout

# ‚úÖ ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å LINE
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    text = event.message.text
    esi_level = classify_esi(text)  # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö ESI

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö ESI ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
    if esi_level in [1, 2]:
        response_text = f"üö® ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ! (ESI {esi_level})"
    elif esi_level == 3:
        response_text = f"ü©∫ ‡∏Ñ‡∏ß‡∏£‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏î‡∏¢‡πÅ‡∏û‡∏ó‡∏¢‡πå (ESI {esi_level})"
    else:
        response_text = f"üíä ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏µ‡πà‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (ESI {esi_level})"

    # ‚úÖ ‡πÉ‡∏ä‡πâ Threading ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LINE ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    def reply():
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_text))

    thread = threading.Thread(target=reply)
    thread.start()

# ‚úÖ ‡∏£‡∏±‡∏ô‡πÅ‡∏≠‡∏õ
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000)
